# WARNING - Generated by {fusen} from dev/flat_dev_5_visualisation2.Rmd: do not edit by hand # nolint: line_length_linter.

#' Generate Humanitarian Data Story from ggplot
#'
#' This function takes a ggplot2 object and generates a storytelling narrative
#' focused on humanitarian insights. It uses the \{ellmer\} package to call
#' a large language model from a supported provider.
#'
#' The narrative can be used as a full‑text explanation or a concise subtitle
#' for plots. The LLM has access to the plot’s data (truncated for efficiency),
#' title, subtitle, and caption. Both provider and model can be chosen explicitly
#' or detected automatically based on which API key environment variable is set.
#'
#' Setup:
#' 1. Install \{ellmer\}: `install.packages("ellmer")`
#' 2. Use Ollama or Set your API key in your environment, for example:
#'    `Sys.setenv(OPENAI_API_KEY = "<YOUR_OPENAI_KEY>")`
#'    `Sys.setenv(GEMINI_API_KEY = "<YOUR_GOOGLE_GEMINI_KEY>")`
#'    `Sys.setenv(ANTHROPIC_API_KEY = "<YOUR_ANTHROPIC_KEY>")`
#'
#' @param plot A `ggplot` object from ggplot2.
#' @param max_tokens Maximum number of tokens (approximate) 
#' for the narrative (default = 30).
#' @param provider Optional character string specifying the provider. Options 
#' include:
#'   `"openai"`, `"gemini"`, `"anthropic"`, `"ollama"`. If `NULL`, 
#'   auto-detect from environment keys.
#' @param model Optional character string specifying the model name. If `NULL`,
#'  a default model for the chosen provider will be used.
#'
#' @return A character string containing a storytelling narrative focused on
#'  humanitarian data.
#'
#' @importFrom ggplot2 ggplot_build
#' @importFrom dplyr mutate mutate_if select
#' @importFrom stringr str_c str_to_lower
#' @importFrom ellmer chat_openai chat_google_gemini chat_anthropic chat_ollama
#' @export
#' @examples
#'
#' library(ggplot2)
#' p <- ggplot(mtcars, aes(x = wt, y = mpg)) +
#'    geom_point() +
#'     unhcrthemes::theme_unhcr(grid = "Y", axis = "X", axis_title = FALSE) +
#'    labs(title = "Vehicle Efficiency",
#'         subtitle = "Fuel consumption vs weight",
#'         caption = "Source: mtcars dataset")
#'
#' story <- generate_plot_story(p)
#' cat(story)
#' # To use as subtitle:
#' p + ggplot2::labs(subtitle = story)
generate_plot_story <- function(plot, 
                                max_tokens = 30,
                                provider = NULL,
                                model = NULL) {
  
  # Extract plot data (first layer) and truncate
  plot_data <- ggplot2::ggplot_build(plot)$data[[1]] |>
    dplyr::mutate_if(is.numeric, round, 2) |>
    head(30)
  plot_data_text <- capture.output(print(plot_data))
  
  # Extract title, subtitle, caption
  labels <- plot$labels
  title    <- if (!is.null(labels$title))    labels$title    else ""
  subtitle <- if (!is.null(labels$subtitle)) labels$subtitle else ""
  caption  <- if (!is.null(labels$caption))  labels$caption  else ""
  
  # Detect geoms used
  geoms <- unique(sapply(plot$layers, function(layer) class(layer$geom)[1]))
  geoms_text <- paste(geoms, collapse = ", ")
  
  # Build prompt
  system_prompt <- paste0(
    "You are a humanitarian data storytelling assistant. ",
    "Create a clear, compelling narrative highlighting humanitarian insights
    from this visualization."
  )
  
  prompt <- paste0(
    "Title: ",    title,    "\n",
    "Subtitle: ", subtitle, "\n",
    "Caption: ",  caption,  "\n\n",
    "Data (first 30 rows):\n", paste(plot_data_text, collapse = "\n"),
    "Consider the type of plot geoms used: ", geoms_text, ".",
    "\n\nWrite a story in plain English, up to about ", max_tokens, " tokens."
  )
  
  # Auto-detect provider if not specified
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      stop("No supported API key found. Set OPENAI_API_KEY, GEMINI_API_KEY,
           ANTHROPIC_API_KEY, or install and set it to a local OLLAMA")
    }
  }
  
  provider <- tolower(provider)
  
  # Set default models if not provided
  if (is.null(model)) {
    model <- switch(
      provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.5-flash",
      anthropic = "claude-sonnet-4",
      ollama = "phi3:latest",
      stop("Invalid provider specified. Choose from 
           'openai', 'gemini', 'anthropic', 'ollama'.")
    )
  }
  
  # Initialize chat object
  chat <- switch(
    provider,
    openai = ellmer::chat_openai(model = model, system_prompt = system_prompt),
    gemini = ellmer::chat_google_gemini(system_prompt = system_prompt,
                base_url = "https://generativelanguage.googleapis.com/v1beta/",
                                        api_key = Sys.getenv("GEMINI_API_KEY")),
    anthropic = ellmer::chat_anthropic(model = model,
                                       system_prompt = system_prompt),
    ollama = ellmer::chat_ollama(model = model, 
                                 system_prompt = system_prompt),
    stop("Invalid provider specified. Choose from
         'openai', 'gemini', 'anthropic', 'ollama'.")
  )
  
  # Send prompt and get response
  response <- chat$chat(prompt)
  
  return(response)
}

