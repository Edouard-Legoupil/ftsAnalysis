---
title: "Humanitarian Funding Flows Analysis  "
subtitle: "`r paste('Destination Profile:', params$name)`"
author: "AI Generated Analysis based on [OCHA Finantial Tracking Service Data API](https://fts.unocha.org/). Beware of data limitations and potential hallucinations! Thanks for reporting any [issues here](https://github.com/Edouard-Legoupil/ftsAnalysis/issues/new) -- [View all Reports](../articles/ai-powered-reports.html)"
format:
  html:
    toc: true
    code-fold: true
    self-contained: true
params:
  name: "Burundi"
---

```{r setup, include=FALSE}
# Set default Quarto options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
# Load necessary libraries 
library(ftsAnalysis)
library(ellmer)
# Access parameters passed during rendering
destination_name <- params$name

p1 <- plot_destination_funding_destination(flows, destination_name)
story1 <- generate_plot_story(p1, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p2 <- plot_destination_funding_donor(flows, destination_name)
story2 <- generate_plot_story(p2, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p3 <- plot_destination_heatmap(flows, destination_name , top_n = 5)
story3 <- generate_plot_story(p3, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

chat =  ellmer::chat_azure_openai(
  system_prompt = "You are a humanitarian funding analyst.Your task is to build a concise executive summary to describe the profile of a specific destination based on provided information",
  model = "gpt-4.1-mini",
  api_version = Sys.getenv("AZURE_OPENAI_API_VERSION"),
  endpoint = Sys.getenv("AZURE_OPENAI_ENDPOINT"),
  api_key = Sys.getenv("AZURE_OPENAI_API_KEY"))



exec <- chat$chat( paste0(" Build a short 300 words Destination Profile for ",
                           destination_name, ". \n. Ground your summary on the below information:",
                           "\n\n - 1 Main Recipient: \n",
                           story1,
                           "\n\n - 2, Main Donors: \n",
                           story2,
                           "\n\n - 3. Matrix: \n",
                           story3,
                          " \n\n INSTRUCTIONS: Do not repeat the provided content - focus on extracting key high level information for a fund raisers audience"
                           
                           ))

```

## Executive Summary

`r exec`

# Main Recipients

`r story1`
  
```{r example-plot_destination_funding_destination}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%


dubbed <- generate_plot_story(p1, provider = "azure", model = "gpt-4.1-mini")
p1 + ggplot2::labs(subtitle = dubbed)
```

# Main Donors

`r story2`
  
```{r example-plot_destination_funding_donor}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%

dubbed <- generate_plot_story(p2, provider = "azure", model = "gpt-4.1-mini")
p2 + ggplot2::labs(subtitle = dubbed)
```

# Matrix

`r story3`
  
```{r example-plot_destination_heatmap}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%

dubbed <- generate_plot_story(p3, provider = "azure", model = "gpt-4.1-mini")
p3 + ggplot2::labs(subtitle = dubbed)
```


  
