---
title: "Humanitarian Funding Flows Analysis  "
subtitle: "`r paste('Recipient Profile:', params$name)`"
author: "AI Generated Analysis based on [OCHA Finantial Tracking Service Data API](https://fts.unocha.org/). Beware of data limitations and potential hallucinations! Thanks for reporting any [issues here](https://github.com/Edouard-Legoupil/ftsAnalysis/issues/new) -- [View all Reports](../articles/ai-powered-reports.html)"
format:
  html:
    toc: true
    code-fold: true
    self-contained: true
params:
  name: "United Nations High Commissioner for Refugees"
---

```{r setup, include=FALSE}
# Set default Quarto options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
# Load necessary libraries 
library(ftsAnalysis)
library(ellmer)
# Access parameters passed during rendering
recipient_name <- params$name

p1 <- plot_recipient_funding_composition(flows, 
              recipient_name )
story1 <- generate_plot_story(p1, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p2 <- plot_recipient_grandbargain(flows,
          recipient_name)
story2 <- generate_plot_story(p2, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p3 <- plot_recipient_cofunding(flows, 
              recipient_name)
story3 <- generate_plot_story(p3, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p4 <- plot_recipient_contribution_type(flows, 
                recipient_name)
story4 <- generate_plot_story(p4, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p5 <- analysis_donor_lifecycle_stage(flows, 
             recipient_name )
story5 <- generate_plot_story(p5, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)

p6 <- analysis_donor_segmentation(flows, 
             recipient_name )
story6 <- generate_plot_story(p6, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)


p6 <- analysis_donor_segmentation(flows, 
             recipient_name )
story6 <- generate_plot_story(p6, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)


p6 <- analysis_donor_segmentation(flows, 
             recipient_name )
story6 <- generate_plot_story(p6, provider = "azure", model = "gpt-4.1-mini", max_tokens = 300)


chat =  ellmer::chat_azure_openai(
  system_prompt = "You are a humanitarian funding analyst.Your task is to build a concise executive summary to describe the profile of a specific recipient based on provided information",
  model = "gpt-4.1-mini",
  api_version = Sys.getenv("AZURE_OPENAI_API_VERSION"),
  endpoint = Sys.getenv("AZURE_OPENAI_ENDPOINT"),
  api_key = Sys.getenv("AZURE_OPENAI_API_KEY"))



exec <- chat$chat( paste0(" Build a short 300 words Recipient Profile for ",
                           destination_name, ". \n. Ground your summary on the below information:",
                           "\n\n - 1. Funding Composition: \n",
                           story1,
                           "\n\n - 2. Funding Flexibility: \n",
                           story2,
                           "\n\n - 3. Cofunding: \n",
                           story3,
                           "\n\n - 4. Contribution Type: \n",
                           story4,
                          " \n\n INSTRUCTIONS: Do not repeat the provided content - focus on extracting key high level information for a fund raisers audience"
                           
                           ))

```

## Executive Summary

`r exec`

## Funding Composition

`r story1`  

```{r example-plot_recipient_funding_composition}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p1, provider = "azure", model = "gpt-4.1-mini")
p1 + ggplot2::labs(subtitle = dubbed)
```

# Funding Flexibility

`r story2`
  
```{r example-plot_recipient_grandbargain}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p2, provider = "azure", model = "gpt-4.1-mini")
p2 + ggplot2::labs(subtitle = dubbed)
```

# Cofunding

`r story3`
  
```{r example-plot_recipient_cofunding}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p3, provider = "azure", model = "gpt-4.1-mini")
p3 + ggplot2::labs(subtitle = dubbed)
```

# Contribution Type

`r story4`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p4, provider = "azure", model = "gpt-4.1-mini")
p4 + ggplot2::labs(subtitle = dubbed)
```

# Sectoral Overview

`r story5`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p5, provider = "azure", model = "gpt-4.1-mini")
p5 + ggplot2::labs(subtitle = dubbed)
```




# Donor Portfolio

`r story6`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p6, provider = "azure", model = "gpt-4.1-mini")
p6 + ggplot2::labs(subtitle = dubbed)
```

# Donor Life Cycle

`r story7`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p7, provider = "azure", model = "gpt-4.1-mini")
p7 + ggplot2::labs(subtitle = dubbed)
```


# Donor Segmentation

`r story8`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p8, provider = "azure", model = "gpt-4.1-mini")
p8 + ggplot2::labs(subtitle = dubbed)
```


# Funding Forecast

`r story9`
  
```{r example-plot_recipient_contribution_type}
#| fig.retina: 2.0
#| fig.width: 8.0
#| fig.asp: 0.618
#| fig.align: center
#| out.width: 90%
dubbed <- generate_plot_story(p9, provider = "azure", model = "gpt-4.1-mini")
p9 + ggplot2::labs(subtitle = dubbed)
```
